


<PubmedArticle>
    <MedlineCitation Status="Publisher" Owner="NLM">
        <PMID Version="1">31199251</PMID>
        <DateRevised>
            <Year>2019</Year>
            <Month>06</Month>
            <Day>14</Day>
        </DateRevised>
        <Article PubModel="Print-Electronic">
            <Journal>
                <ISSN IssnType="Electronic">1939-3539</ISSN>
                <JournalIssue CitedMedium="Internet">
                    <PubDate>
                        <Year>2019</Year>
                        <Month>Jun</Month>
                        <Day>11</Day>
                    </PubDate>
                </JournalIssue>
                <Title>IEEE transactions on pattern analysis and machine intelligence</Title>
                <ISOAbbreviation>IEEE Trans Pattern Anal Mach Intell</ISOAbbreviation>
            </Journal>
            <ArticleTitle>Vocabulary-informed Zero-shot and Open-set Learning.</ArticleTitle>
            <ELocationID EIdType="doi" ValidYN="Y">10.1109/TPAMI.2019.2922175</ELocationID>
            <Abstract>
                <AbstractText>Despite significant progress in object categorization, in recent years, a number of important challenges remain; mainly, ability to learn from limited labeled data and ability to recognize object classes within large, potentially open, set of labels. Zero-shot learning is one way of addressing these challenges, but it has only been shown to work with limited sized class vocabularies and typically requires separation between supervised and unsupervised classes, allowing former to inform the latter but not vice versa. We propose the notion of vocabulary-informed learning to alleviate the above mentioned challenges and address problems of supervised, zero-shot, generalized zero-shot and open set recognition using a unified framework. Specifically, we propose a weighted maximum margin framework for semantic manifold-based recognition that incorporates distance constraints from (both supervised and unsupervised) vocabulary atoms. Distance constraints ensure that labeled samples are projected closer to their correct prototypes, in the embedding space, than to others. We illustrate that resulting model shows improvements in supervised, zero-shot, generalized zero-shot, and large open set recognition, with up to 310K class vocabulary on AwA and ImageNet datasets.</AbstractText>
            </Abstract>
            <AuthorList CompleteYN="Y">
                <Author ValidYN="Y">
                    <LastName>Fu</LastName>
                    <ForeName>Yanwei</ForeName>
                    <Initials>Y</Initials>
                </Author>
                <Author ValidYN="Y">
                    <LastName>Wang</LastName>
                    <ForeName>Xiaomei</ForeName>
                    <Initials>X</Initials>
                </Author>
                <Author ValidYN="Y">
                    <LastName>Dong</LastName>
                    <ForeName>Hanze</ForeName>
                    <Initials>H</Initials>
                </Author>
                <Author ValidYN="Y">
                    <LastName>Jiang</LastName>
                    <ForeName>Yu-Gang</ForeName>
                    <Initials>YG</Initials>
                </Author>
                <Author ValidYN="Y">
                    <LastName>Wang</LastName>
                    <ForeName>Meng</ForeName>
                    <Initials>M</Initials>
                </Author>
                <Author ValidYN="Y">
                    <LastName>Xue</LastName>
                    <ForeName>Xiangyang</ForeName>
                    <Initials>X</Initials>
                </Author>
                <Author ValidYN="Y">
                    <LastName>Sigal</LastName>
                    <ForeName>Leonid</ForeName>
                    <Initials>L</Initials>
                </Author>
            </AuthorList>
            <Language>eng</Language>
            <PublicationTypeList>
                <PublicationType UI="D016428">Journal Article</PublicationType>
            </PublicationTypeList>
            <ArticleDate DateType="Electronic">
                <Year>2019</Year>
                <Month>06</Month>
                <Day>11</Day>
            </ArticleDate>
        </Article>
        <MedlineJournalInfo>
            <Country>United States</Country>
            <MedlineTA>IEEE Trans Pattern Anal Mach Intell</MedlineTA>
            <NlmUniqueID>9885960</NlmUniqueID>
            <ISSNLinking>0098-5589</ISSNLinking>
        </MedlineJournalInfo>
    </MedlineCitation>
    <PubmedData>
        <History>
            <PubMedPubDate PubStatus="entrez">
                <Year>2019</Year>
                <Month>6</Month>
                <Day>15</Day>
                <Hour>6</Hour>
                <Minute>0</Minute>
            </PubMedPubDate>
            <PubMedPubDate PubStatus="pubmed">
                <Year>2019</Year>
                <Month>6</Month>
                <Day>15</Day>
                <Hour>6</Hour>
                <Minute>0</Minute>
            </PubMedPubDate>
            <PubMedPubDate PubStatus="medline">
                <Year>2019</Year>
                <Month>6</Month>
                <Day>15</Day>
                <Hour>6</Hour>
                <Minute>0</Minute>
            </PubMedPubDate>
        </History>
        <PublicationStatus>aheadofprint</PublicationStatus>
        <ArticleIdList>
            <ArticleId IdType="pubmed">31199251</ArticleId>
            <ArticleId IdType="doi">10.1109/TPAMI.2019.2922175</ArticleId>
        </ArticleIdList>
    </PubmedData>
</PubmedArticle>

